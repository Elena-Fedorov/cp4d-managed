{
    "componentChunkName": "component---src-pages-iacs-offering-run-on-existing-openshift-mdx",
    "path": "/IACS-Offering/run-on-existing-openshift/",
    "result": {"pageContext":{"frontmatter":{"title":"Run on existing OpenShift cluster","tabs":["Run on IBM Cloud","Run on vSphere","Run on AWS","Run on existing OpenShift"]},"relativePagePath":"/IACS-Offering/run-on-existing-openshift.mdx","titleType":"page","MdxNode":{"id":"7d99aa7d-a507-5bb9-be70-6c34d08b9b73","children":[],"parent":"c60f2873-d7aa-5503-9e11-28fc87104b32","internal":{"content":"---\ntitle: Run on existing OpenShift cluster\ntabs: ['Run on IBM Cloud', 'Run on vSphere', 'Run on AWS', 'Run on existing OpenShift']\n---\n\n# Running the Cloud Pak Deployer on an existing OpenShift cluster\nWhen running the Cloud Pak Deployer on an existing OpenShift cluster, the following is assumed:\n* The OpenShift cluster is up and running with sufficient worker nodes\n* The appropriate storage class(es) have been pre-created\n* You have cluster administrator permissions to OpenShift\n\n## Acquire an IBM Cloud Pak Entitlement Key\nIf you want to pull the Cloud Pak images from the entitled registry (i.e. an online install), or if you want to mirror the images to your private registry, you need to download the entitlement key. You can skip this step if you're installing from a private registry and all Cloud Pak images have already been downloaded to the private registry.\n- Navigate to https://myibm.ibm.com/products-services/containerlibrary and login with your IBMId credentials\n- Select **Get Entitlement Key** and create a new key (or copy your existing key)\n- Copy the key value\n\n<InlineNotification kind=\"warning\">\nAs stated for the API key, you can choose to download the entitlement key to a file. However, when we reference the entitlement key, we mean the 80+ character string that is displayed, not the file.\n</InlineNotification>\n\n## Prepare for running\n\n### Set environment variables\n```\nexport CP_ENTITLEMENT_KEY=your_cp_entitlement_key\n\nexport STATUS_DIR=/data/status/sample\nexport CONFIG_DIR=/data/config/sample\n```\n\n* `CP_ENTITLEMENT_KEY`: This is the entitlement key you acquired as per the instructions above, this is a 80+ character string\n* `STATUS_DIR`: The directory where the Cloud Pak Deployer keeps all status information and logs files. **Please note** that if you have chosen to use a File Vault, the properties file is keps under the `vault` directory within the status directory\n* `CONFIG_DIR`: Directory that holds the configuration, it must have `config`, `defaults` and `inventory` subdirectories\n\n<InlineNotification>\nCloud Pak Deployer uses the status directory to logs its activities and also to keep track of its running state. For a given environment you're provisioning or destroying, you should always specify the same status directory to avoid contention between different deploy runs. You can run the Cloud Pak Deployer in parallel for different environments (different configuration directories).\n</InlineNotification>\n\n### Log in to OpenShift and store `kubeconfig` secret\nBecause you will be deploying the Cloud Pak on an existing OpenShift cluster, the deployer needs to be able to access OpenShift. Rather than the many variations of OpenShift authentication that could be applicable, the deployer expects a `kubeconfig` file with the cluster's credentials to be stored as a secret in the vault.\n\n* Log in to OpenShift as a cluster administrator using your method of choice\n* Locate the Kubernetes config file. If you have logged in with the OpenShift client, thie is typically `~/.kube/config`\n* Now, store the Kubernetes config file as a vault secret\n\n```\n./cp-deploy.sh vault set \\\n    --vault-secret kubeconfig \\\n    --vault-secret-file ~/.kube/config\n```\n\nThe deployer will retrieve this secret from the vault when it requires access to OpenShift. If the secret cannot be found or if it is invalid or the OpenShift login token has expired, the deployer will fail and you will need to update the secret with a valid Kubernetes config file.\n\n## Run the Cloud Pak Deployer\nTo run the container using a local configuration input directory and a data directory where temporary and state is kept, use the example below. If you don't specify the status directory, the deployer will automatically create a temporary directory. Please note that the status directory will also hold secrets if you have configured a flat file vault. If you lose the directory, you will not be able to make changes to the configuration and adjust the deployment. It is best to specify a permanent directory that you can reuse later. If you specify an existing directory the current user **must** be the owner of the directory. Failing to do so may cause the container to fail with insufficient permissions.\n```\n./cp-deploy.sh env apply\n```\n\nIf you have chosen to use dynamic properties (extra variables), you can specify these on the command line, see below. Extra variables are covered in [advanced configuration](/advanced/advanced-configuration).\n```\n./cp-deploy.sh env apply -e env_id=acme-01\n```\n\nIn the above command, the `env_id` extra variable defines the names of the objects that are being created; these are referenced in the `.yaml` configuration files as `{{ env_id }}`. For more information about the extra (dynamic) variables, see [advanced configuration](/advanced/advanced-configuration).\n\nWhen running the command, the container will start as a daemon and the command will tail-follow the logs. You can press Ctrl-C at any time to interrupt the logging but the container will continue to run in the background.\n\nYou can return to view the logs as follows:\n```\n./cp-deploy.sh env logs\n```\n\nPreparing OpenShift and installing the Cloud Pak will take a long time, typically between 1-5 hours,dependent on which Cloud Pak cartridges you configured. For estimated duration of the steps, refer to [Timings](/cpd-design/timings).\n\nIf you need to interrupt the automation, use CTRL-C to stop the logging output and then use:\n```\n./cp-deploy.sh env kill\n```\n\n## On failure\nIf the Cloud Pak Deployer fails, for example because certain infrastructure components are temporarily not available, fix the cause if needed and then just re-run it with the same `CONFIG_DIR` and `STATUS_DIR` as well extra variables. The provisioning process has been designed to be idempotent and it will not redo actions that have already completed successfully.\n\n## Finishing up\nOnce the process has finished, it will output the URLs by which you can access the deployed Cloud Pak. You can also find this information under the `cloud-paks` directory in the status directory you specified.\n\nTo retrieve the Cloud Pak URL(s):\n```\ncat $STATUS_DIR/cloud-paks/*\n```\n\nThis will show the Cloud Pak URLs:\n```output\nCloud Pak for Data URL for cluster acme-01 and project zen-40:\nhttps://cpd-zen-40.apps.acme-01.example.com\n```\n\nList the secrets in the vault:\n```\n./cp-deploy.sh vault list\n```\n\nThis will show something similar to the following:\n```output\nSecret list for group sample:\n- ibm_cp_entitlement_key\n- kubeconfig\n- cp4d_admin_zen_sample_sample\n```\n\nYou can then retrieve the Cloud Pak for Data admin password like this:\n```\n./cp-deploy.sh vault get --vault-secret cp4d_admin_zen_sample_sample\n```\n\n```output\nPLAY [Secrets] *****************************************************************\nincluded: /automation_script/automation-roles/99-generic/vault/vault-get-secret/tasks/get-secret-file.yml for localhost\ncp4d_admin_zen_sample_sample: gelGKrcgaLatBsnAdMEbmLwGr\n```","type":"Mdx","contentDigest":"e1374a4b44161f4e63c6fb2f012cf010","owner":"gatsby-plugin-mdx","counter":267},"frontmatter":{"title":"Run on existing OpenShift cluster","tabs":["Run on IBM Cloud","Run on vSphere","Run on AWS","Run on existing OpenShift"]},"exports":{},"rawBody":"---\ntitle: Run on existing OpenShift cluster\ntabs: ['Run on IBM Cloud', 'Run on vSphere', 'Run on AWS', 'Run on existing OpenShift']\n---\n\n# Running the Cloud Pak Deployer on an existing OpenShift cluster\nWhen running the Cloud Pak Deployer on an existing OpenShift cluster, the following is assumed:\n* The OpenShift cluster is up and running with sufficient worker nodes\n* The appropriate storage class(es) have been pre-created\n* You have cluster administrator permissions to OpenShift\n\n## Acquire an IBM Cloud Pak Entitlement Key\nIf you want to pull the Cloud Pak images from the entitled registry (i.e. an online install), or if you want to mirror the images to your private registry, you need to download the entitlement key. You can skip this step if you're installing from a private registry and all Cloud Pak images have already been downloaded to the private registry.\n- Navigate to https://myibm.ibm.com/products-services/containerlibrary and login with your IBMId credentials\n- Select **Get Entitlement Key** and create a new key (or copy your existing key)\n- Copy the key value\n\n<InlineNotification kind=\"warning\">\nAs stated for the API key, you can choose to download the entitlement key to a file. However, when we reference the entitlement key, we mean the 80+ character string that is displayed, not the file.\n</InlineNotification>\n\n## Prepare for running\n\n### Set environment variables\n```\nexport CP_ENTITLEMENT_KEY=your_cp_entitlement_key\n\nexport STATUS_DIR=/data/status/sample\nexport CONFIG_DIR=/data/config/sample\n```\n\n* `CP_ENTITLEMENT_KEY`: This is the entitlement key you acquired as per the instructions above, this is a 80+ character string\n* `STATUS_DIR`: The directory where the Cloud Pak Deployer keeps all status information and logs files. **Please note** that if you have chosen to use a File Vault, the properties file is keps under the `vault` directory within the status directory\n* `CONFIG_DIR`: Directory that holds the configuration, it must have `config`, `defaults` and `inventory` subdirectories\n\n<InlineNotification>\nCloud Pak Deployer uses the status directory to logs its activities and also to keep track of its running state. For a given environment you're provisioning or destroying, you should always specify the same status directory to avoid contention between different deploy runs. You can run the Cloud Pak Deployer in parallel for different environments (different configuration directories).\n</InlineNotification>\n\n### Log in to OpenShift and store `kubeconfig` secret\nBecause you will be deploying the Cloud Pak on an existing OpenShift cluster, the deployer needs to be able to access OpenShift. Rather than the many variations of OpenShift authentication that could be applicable, the deployer expects a `kubeconfig` file with the cluster's credentials to be stored as a secret in the vault.\n\n* Log in to OpenShift as a cluster administrator using your method of choice\n* Locate the Kubernetes config file. If you have logged in with the OpenShift client, thie is typically `~/.kube/config`\n* Now, store the Kubernetes config file as a vault secret\n\n```\n./cp-deploy.sh vault set \\\n    --vault-secret kubeconfig \\\n    --vault-secret-file ~/.kube/config\n```\n\nThe deployer will retrieve this secret from the vault when it requires access to OpenShift. If the secret cannot be found or if it is invalid or the OpenShift login token has expired, the deployer will fail and you will need to update the secret with a valid Kubernetes config file.\n\n## Run the Cloud Pak Deployer\nTo run the container using a local configuration input directory and a data directory where temporary and state is kept, use the example below. If you don't specify the status directory, the deployer will automatically create a temporary directory. Please note that the status directory will also hold secrets if you have configured a flat file vault. If you lose the directory, you will not be able to make changes to the configuration and adjust the deployment. It is best to specify a permanent directory that you can reuse later. If you specify an existing directory the current user **must** be the owner of the directory. Failing to do so may cause the container to fail with insufficient permissions.\n```\n./cp-deploy.sh env apply\n```\n\nIf you have chosen to use dynamic properties (extra variables), you can specify these on the command line, see below. Extra variables are covered in [advanced configuration](/advanced/advanced-configuration).\n```\n./cp-deploy.sh env apply -e env_id=acme-01\n```\n\nIn the above command, the `env_id` extra variable defines the names of the objects that are being created; these are referenced in the `.yaml` configuration files as `{{ env_id }}`. For more information about the extra (dynamic) variables, see [advanced configuration](/advanced/advanced-configuration).\n\nWhen running the command, the container will start as a daemon and the command will tail-follow the logs. You can press Ctrl-C at any time to interrupt the logging but the container will continue to run in the background.\n\nYou can return to view the logs as follows:\n```\n./cp-deploy.sh env logs\n```\n\nPreparing OpenShift and installing the Cloud Pak will take a long time, typically between 1-5 hours,dependent on which Cloud Pak cartridges you configured. For estimated duration of the steps, refer to [Timings](/cpd-design/timings).\n\nIf you need to interrupt the automation, use CTRL-C to stop the logging output and then use:\n```\n./cp-deploy.sh env kill\n```\n\n## On failure\nIf the Cloud Pak Deployer fails, for example because certain infrastructure components are temporarily not available, fix the cause if needed and then just re-run it with the same `CONFIG_DIR` and `STATUS_DIR` as well extra variables. The provisioning process has been designed to be idempotent and it will not redo actions that have already completed successfully.\n\n## Finishing up\nOnce the process has finished, it will output the URLs by which you can access the deployed Cloud Pak. You can also find this information under the `cloud-paks` directory in the status directory you specified.\n\nTo retrieve the Cloud Pak URL(s):\n```\ncat $STATUS_DIR/cloud-paks/*\n```\n\nThis will show the Cloud Pak URLs:\n```output\nCloud Pak for Data URL for cluster acme-01 and project zen-40:\nhttps://cpd-zen-40.apps.acme-01.example.com\n```\n\nList the secrets in the vault:\n```\n./cp-deploy.sh vault list\n```\n\nThis will show something similar to the following:\n```output\nSecret list for group sample:\n- ibm_cp_entitlement_key\n- kubeconfig\n- cp4d_admin_zen_sample_sample\n```\n\nYou can then retrieve the Cloud Pak for Data admin password like this:\n```\n./cp-deploy.sh vault get --vault-secret cp4d_admin_zen_sample_sample\n```\n\n```output\nPLAY [Secrets] *****************************************************************\nincluded: /automation_script/automation-roles/99-generic/vault/vault-get-secret/tasks/get-secret-file.yml for localhost\ncp4d_admin_zen_sample_sample: gelGKrcgaLatBsnAdMEbmLwGr\n```","fileAbsolutePath":"/Users/kanimozhin/Documents/Github/cp4d-managed/src/pages/IACS-Offering/run-on-existing-openshift.mdx"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}